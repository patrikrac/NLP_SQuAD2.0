{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPyN3uygocGiMat+E7tts1Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/patrikrac/NLP_SQuAD2.0/blob/main/few_shot_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3I6MV9LYWgS",
        "outputId": "c91dc7f3-acd4-4c46-a8bd-015cbe638e7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.26.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.35.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.16.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.1.99)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.20.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install transformers\n",
        "! pip install sentencepiece\n",
        "! pip install accelerate\n",
        "! pip -q install hnswlib\n",
        "! pip install sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "generative_tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-large\")\n",
        "generative_model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-large\", device_map=\"auto\", torch_dtype=torch.float16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNMMOve6Y1mU",
        "outputId": "970b8145-af34-4d45-e40b-0f72ae6590cc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "if device.type != 'cuda':\n",
        "    raise SystemError('GPU device not found')"
      ],
      "metadata": {
        "id": "bv9as75_Z-nP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = 'Translate the following sentence from Italian to English: \"Amo la pizza\"'\n",
        "input_ids = generative_tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device)\n",
        "\n",
        "output_ids = generative_model.generate(input_ids, max_new_tokens=32)\n",
        "output_text = generative_tokenizer.decode(output_ids[0])\n",
        "print(output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gX5RUbCFZXOF",
        "outputId": "529e3c8b-f4e4-4139-b5af-d2b490ed0c2d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<pad> \"I love pizza\"</s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkbN6nlXB6b2",
        "outputId": "b835c16d-5551-4525-848e-11d89bf47f21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading the TRAIN dataset of SQuAD2.0\n",
            "--2024-01-13 10:27:13--  https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json\n",
            "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.108.153, 185.199.109.153, 185.199.110.153, ...\n",
            "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.108.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 42123633 (40M) [application/json]\n",
            "Saving to: ‘train-v2.0.json.1’\n",
            "\n",
            "train-v2.0.json.1   100%[===================>]  40.17M   106MB/s    in 0.4s    \n",
            "\n",
            "2024-01-13 10:27:13 (106 MB/s) - ‘train-v2.0.json.1’ saved [42123633/42123633]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Download the dataset\n",
        "print(\"Downloading the TRAIN dataset of SQuAD2.0\")\n",
        "!wget https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "lVVCMhZfE9Hl",
        "outputId": "3e1f41dd-1328-4a0b-984c-f4f6453e9cd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of the dataset: 884 (e.g. Categories of questions)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  version                                               data\n",
              "0    v2.0  {'title': 'Beyoncé', 'paragraphs': [{'qas': [{...\n",
              "1    v2.0  {'title': 'Frédéric_Chopin', 'paragraphs': [{'...\n",
              "2    v2.0  {'title': 'Sino-Tibetan_relations_during_the_M...\n",
              "3    v2.0  {'title': 'IPod', 'paragraphs': [{'qas': [{'qu...\n",
              "4    v2.0  {'title': 'The_Legend_of_Zelda:_Twilight_Princ..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-67fe645f-09d7-4996-9c9a-a737ba04d2f2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>version</th>\n",
              "      <th>data</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>v2.0</td>\n",
              "      <td>{'title': 'Beyoncé', 'paragraphs': [{'qas': [{...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>v2.0</td>\n",
              "      <td>{'title': 'Frédéric_Chopin', 'paragraphs': [{'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>v2.0</td>\n",
              "      <td>{'title': 'Sino-Tibetan_relations_during_the_M...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>v2.0</td>\n",
              "      <td>{'title': 'IPod', 'paragraphs': [{'qas': [{'qu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>v2.0</td>\n",
              "      <td>{'title': 'The_Legend_of_Zelda:_Twilight_Princ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-67fe645f-09d7-4996-9c9a-a737ba04d2f2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-67fe645f-09d7-4996-9c9a-a737ba04d2f2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-67fe645f-09d7-4996-9c9a-a737ba04d2f2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b890e986-6979-49a6-bdfa-fad8cca3ca18\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b890e986-6979-49a6-bdfa-fad8cca3ca18')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b890e986-6979-49a6-bdfa-fad8cca3ca18 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import pandas\n",
        "dataframe = pandas.read_json(\"./train-v2.0.json\")\n",
        "print(f\"Size of the dataset: {dataframe.size} (e.g. Categories of questions)\")\n",
        "dataframe.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We will now create a list with pairs (Title, Question, Paragraph, Answers)\n",
        "data_list = list()\n",
        "categories = list()\n",
        "paragraphs = list()\n",
        "questions = list()\n",
        "\n",
        "for _, row in dataframe.iterrows():\n",
        "  categories.append(row[\"data\"][\"title\"])\n",
        "  for p in row[\"data\"][\"paragraphs\"]:\n",
        "    paragraphs.append(p[\"context\"])\n",
        "    for q in p[\"qas\"]:\n",
        "      questions.append(q[\"question\"])\n",
        "      data_list.append((row[\"data\"][\"title\"], q, p[\"context\"], q[\"answers\"]))"
      ],
      "metadata": {
        "id": "BPSd_7I_mtPP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(data_list))\n",
        "\n",
        "i = 3\n",
        "print(questions[i])\n",
        "print(data_list[i][2])\n",
        "print(data_list[i][3])\n",
        "print((data_list[i][3][0]['text']))\n",
        "print(data_list[i][1][\"is_impossible\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEwmMN1sskoY",
        "outputId": "039605bf-11ff-486f-f874-84573a074363"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "130319\n",
            "In what city and state did Beyonce  grow up? \n",
            "Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".\n",
            "[{'text': 'Houston, Texas', 'answer_start': 166}]\n",
            "Houston, Texas\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "random.seed(42)\n",
        "\n",
        "idx = random.choice(range(len(questions)))\n",
        "\n",
        "question = questions[idx]\n",
        "\n",
        "print(f'Question {idx}: {question}?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_QDWP2Ou3gi",
        "outputId": "0cdf3c69-a058-4d3f-d1d5-25e5dbb246ca"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question 83810: What century did Nasser rule in??\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
        "\n",
        "semb_model = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')\n",
        "xenc_model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')"
      ],
      "metadata": {
        "id": "d9W7MgqxbTXZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "8DO9OtdA9xxf",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fc3ad99-a2db-42a2-dd0e-6f8ce90986ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading embeddings cache\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pickle\n",
        "\n",
        "# Define hnswlib index path\n",
        "embeddings_cache_path = './qa_embeddings_cache.pkl'\n",
        "\n",
        "# Load cache if available\n",
        "if os.path.exists(embeddings_cache_path):\n",
        "    print('Loading embeddings cache')\n",
        "    with open(embeddings_cache_path, 'rb') as f:\n",
        "        corpus_embeddings = pickle.load(f)\n",
        "# Else compute embeddings\n",
        "else:\n",
        "    print('Computing embeddings')\n",
        "    corpus_embeddings = semb_model.encode(paragraphs, convert_to_tensor=True, show_progress_bar=True)\n",
        "    # Save the index to a file for future loading\n",
        "    print(f'Saving index to: \\'{embeddings_cache_path}\\'')\n",
        "    with open(embeddings_cache_path, 'wb') as f:\n",
        "        pickle.dump(corpus_embeddings, f)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import hnswlib\n",
        "import time\n",
        "start = time.time()\n",
        "# Create empthy index\n",
        "index = hnswlib.Index(space='cosine', dim=corpus_embeddings.size(1))\n",
        "\n",
        "# Define hnswlib index path\n",
        "index_path = './qa_hnswlib_100.index'\n",
        "\n",
        "# Load index if available\n",
        "if os.path.exists(index_path):\n",
        "    print('Loading index...')\n",
        "    index.load_index(index_path)\n",
        "# Else index data collection\n",
        "else:\n",
        "    # Initialise the index\n",
        "    print('Start creating HNSWLIB index')\n",
        "    index.init_index(max_elements=corpus_embeddings.size(0), ef_construction=100, M=64) # see https://github.com/nmslib/hnswlib/blob/master/ALGO_PARAMS.md for parameter description\n",
        "    # Compute the HNSWLIB index (it may take a while)\n",
        "    index.add_items(corpus_embeddings.cpu(), list(range(len(corpus_embeddings))))\n",
        "    # Save the index to a file for future loading\n",
        "    print(f'Saving index to: {index_path}')\n",
        "    index.save_index(index_path)\n",
        "\n",
        "end = time.time()\n",
        "print(f\"Exectution time: {int((end - start) / 60)}:{int((end - start) % 60)} min:sec\")"
      ],
      "metadata": {
        "id": "9UfVrlqkd5qS",
        "outputId": "f588f2d3-2aed-4725-dac4-5884afbb4b75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading index...\n",
            "Exectution time: 0:0 min:sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_paragraphs(semb_model, xenc_model, question, topp):\n",
        "  \"\"\"\n",
        "  Samples the topp most relevant paragraphs for the given quesion embedding\n",
        "  \"\"\"\n",
        "  question_embedding = semb_model.encode(question, convert_to_tensor=True)\n",
        "  corpus_ids, _ = index.knn_query(question_embedding.cpu(), k=128)\n",
        "\n",
        "  model_inputs = [(question, paragraphs[idx]) for idx in corpus_ids[0]]\n",
        "  cross_scores = xenc_model.predict(model_inputs)\n",
        "\n",
        "  #print(\"Cross-encoder model re-ranking results\")\n",
        "  #print(f\"Query: \\\"{question}\\\"\")\n",
        "  #print(\"---------------------------------------\")\n",
        "  #for idx in np.argsort(-cross_scores)[:3]:\n",
        "  #  print(f\"Score: {cross_scores[idx]:.4f}\\nDocument: \\\"{paragraphs[corpus_ids[0][idx]]}\\\"\\n\\n\")\n",
        "\n",
        "  return np.argsort(-cross_scores)[:topp], corpus_ids"
      ],
      "metadata": {
        "id": "W3FFzcr_8cit"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "print(dataframe.shape)\n",
        "print(dataframe.index)\n",
        "print(dataframe.columns)\n",
        "print(dataframe.loc[0, 'data']['title'])\n",
        "def qa_pipeline(\n",
        "    question,\n",
        "    similarity_model=semb_model,\n",
        "    embeddings_index=index,\n",
        "    re_ranking_model=xenc_model,\n",
        "    generative_model=generative_model,\n",
        "    device=device,\n",
        "    shots=0,\n",
        "    top_p=1\n",
        "):\n",
        "    if not question.endswith('?'):\n",
        "        question = question + '?'\n",
        "    # Embed question\n",
        "    #question_embedding = similarity_model.encode(question, convert_to_tensor=True)\n",
        "    # Search documents similar to question in index\n",
        "    #corpus_ids, distances = embeddings_index.knn_query(question_embedding.cpu(), k=128)\n",
        "    # Re-rank results\n",
        "    #xenc_model_inputs = [(question, paragraphs[idx]) for idx in corpus_ids[0]]\n",
        "    #cross_scores = re_ranking_model.predict(xenc_model_inputs)\n",
        "    # Get best matching passage\n",
        "    top_p_idx, corpus_ids = get_paragraphs(similarity_model, re_ranking_model, question, top_p)\n",
        "    # top_p_idx = np.argsort(-cross_scores)[:top_p]\n",
        "    # Encode input\n",
        "    input_text = \"\"\n",
        "    for i in range(shots):\n",
        "      idx = random.choice(range(len(questions)))\n",
        "      while (data_list[idx][1]['is_impossible']) :\n",
        "        idx = random.choice(range(len(questions)))\n",
        "      quest = data_list[idx][1]\n",
        "      passage = data_list[idx][2]\n",
        "      if len(data_list[idx][3]) == 1:\n",
        "        answer = data_list[idx][3]['text']\n",
        "      else:\n",
        "        answer = data_list[idx][3][0]['text']\n",
        "      input_text += f\"passage:\\n{passage}\\n\\nquestion:\\n{quest}\\n\\n{answer}\\n\\n\\n\"\n",
        "      while not(data_list[idx][1]['is_impossible']) :\n",
        "        idx = random.choice(range(len(questions)))\n",
        "      quest = data_list[idx][1]\n",
        "      passage = data_list[idx][2]\n",
        "      input_text += f\"passage:\\n{passage}\\n\\nquestion:\\n{quest}\\n\\nI do not know the answer\\n\\n\\n\"\n",
        "\n",
        "    possible_answer = \"\"\n",
        "    for passage_idx in top_p_idx:\n",
        "      temp_input_text = input_text\n",
        "      passage = paragraphs[corpus_ids[0][passage_idx]]\n",
        "      temp_input_text += f\"Given the following passage, answer the related question.\\n\\nPassage:\\n\\n{passage}\\n\\nQ: {question}\"\n",
        "      #print('INPUT TEXT:', temp_input_text, \"\\n\")\n",
        "      input_ids = generative_tokenizer(temp_input_text, return_tensors=\"pt\").input_ids.to(device)\n",
        "      # Generate output\n",
        "      output_ids = generative_model.generate(input_ids, max_new_tokens=512)\n",
        "      # Decode output\n",
        "      output_text = generative_tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "      possible_answer += output_text + \"\\n\"\n",
        "\n",
        "\n",
        "    input_text = f\"Given the question {question}, choose the best answer between\\n{possible_answer}\"\n",
        "    print('INPUT TEXT:', input_text, \"\\n\")\n",
        "    input_ids = generative_tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device)\n",
        "    # Generate output\n",
        "    output_ids = generative_model.generate(input_ids, max_new_tokens=512)\n",
        "    # Decode output\n",
        "    output_text = generative_tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    return output_text\n",
        "\n",
        "print(dataframe.loc[0, 'data']['paragraphs'][0].keys())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Hqbatb5hZVZ",
        "outputId": "5881ec2f-db4a-4ff9-e98a-5c8da75d74f3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(442, 2)\n",
            "RangeIndex(start=0, stop=442, step=1)\n",
            "Index(['version', 'data'], dtype='object')\n",
            "Beyoncé\n",
            "dict_keys(['qas', 'context'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "ans = qa_pipeline(\"Where is Normandy\", shots=0, top_p=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZWCLrlamzyr",
        "outputId": "ed23a89d-c7ef-47f9-b78b-303d14f3f5f3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INPUT TEXT: Given the question Where is Normandy?, choose the best answer between\n",
            "northern Europe\n",
            "the Atlantic and northern shores\n",
            "England\n",
            " \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ans)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbyzdUOFwle2",
        "outputId": "2b9a2bca-91d1-48f3-deed-2d34a7261c25"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "northern Europe the Atlantic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YAD_CNGrTh6E"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}